{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "premium"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/bodhivani/RAVEfold/blob/main/heavydemo.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Install ColabFold\n",
        "# setup device\n",
        "from IPython.display import clear_output\n",
        "!mkdir struct_gen\n",
        "%cd /content/struct_gen/.\n",
        "clear_output()\n",
        "\n",
        "import warnings\n",
        "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
        "\n",
        "import os\n",
        "import sys\n",
        "import tensorflow as tf\n",
        "import jax\n",
        "\n",
        "try:\n",
        "  # check if TPU is available\n",
        "  import jax.tools.colab_tpu\n",
        "  jax.tools.colab_tpu.setup_tpu()\n",
        "  print('Running on TPU')\n",
        "  DEVICE = \"tpu\"\n",
        "except:\n",
        "  if jax.local_devices()[0].platform == 'cpu':\n",
        "    print(\"WARNING: no GPU detected, will be using CPU\")\n",
        "    DEVICE = \"cpu\"\n",
        "  else:\n",
        "    print('Running on GPU')\n",
        "    DEVICE = \"gpu\"\n",
        "    # disable GPU on tensorflow\n",
        "    tf.config.set_visible_devices([], 'GPU')\n",
        "\n",
        "from IPython.utils import io\n",
        "import subprocess\n",
        "import tqdm.notebook\n",
        "\n",
        "\n",
        "install_jackhmmer = True      #not required\n",
        "\n",
        "#AF2 repo from deepmind\n",
        "GIT_REPO = 'https://github.com/deepmind/alphafold'\n",
        "#AF2 params\n",
        "SOURCE_URL = 'https://storage.googleapis.com/alphafold/alphafold_params_2021-07-14.tar'\n",
        "\n",
        "PARAMS_DIR = './alphafold/data/params'\n",
        "PARAMS_PATH = os.path.join(PARAMS_DIR, os.path.basename(SOURCE_URL))\n",
        "\n",
        "TMP_DIR = \"tmp\"\n",
        "os.makedirs(TMP_DIR, exist_ok=True)\n",
        "\n",
        "#tqdm specification\n",
        "TQDM_BAR_FORMAT = '{l_bar}{bar}| {n_fmt}/{total_fmt} [elapsed: {elapsed} remaining: {remaining}]'\n",
        "# if not already installed\n",
        "total = 55\n",
        "with tqdm.notebook.tqdm(total=total, bar_format=TQDM_BAR_FORMAT) as pbar:\n",
        "  if not os.path.isdir(\"alphafold\"):\n",
        "    # download alphafold code and clone colabfold repo\n",
        "    os.system(f\"git clone {GIT_REPO} alphafold; cd alphafold; git checkout 1d43aaff941c84dc56311076b58795797e49107b\")\n",
        "    os.system(f\"git clone https://github.com/sokrypton/ColabFold.git\")\n",
        "\n",
        "    # apply patches\n",
        "    os.system(f\"patch -u alphafold/alphafold/model/model.py -i ColabFold/beta/model.patch\")\n",
        "    os.system(f\"patch -u alphafold/alphafold/model/mapping.py -i ColabFold/beta/mapping.patch\")\n",
        "    os.system(f\"patch -u alphafold/alphafold/model/modules.py -i ColabFold/beta/modules.patch\")\n",
        "    os.system(f\"patch -u alphafold/alphafold/model/folding.py -i ColabFold/beta/folding.patch\")\n",
        "    os.system(f\"patch -u alphafold/alphafold/model/config.py -i ColabFold/beta/config.patch\")\n",
        "    # apply multi-chain patch from Lim Heo @huhlim\n",
        "    os.system(f\"patch -u alphafold/alphafold/common/protein.py -i ColabFold/beta/protein.patch\")\n",
        "    pbar.update(4)\n",
        "\n",
        "    #install biopython\n",
        "    os.system(f\"pip install biopython dm-haiku==0.0.5 ml-collections py3Dmol\")\n",
        "    pbar.update(6)\n",
        "\n",
        "    # download model params (speedup from kaczmarj)\n",
        "    os.system(f\"mkdir --parents {PARAMS_DIR}\")\n",
        "    os.system(f\"curl -fsSL {SOURCE_URL} | tar x -C {PARAMS_DIR}\")\n",
        "    pbar.update(14+27)\n",
        "\n",
        "    # install hhsuite\n",
        "    os.system(f\"curl -fsSL https://github.com/soedinglab/hh-suite/releases/download/v3.3.0/hhsuite-3.3.0-SSE2-Linux.tar.gz | tar xz -C {TMP_DIR}/\")\n",
        "\n",
        "    # install jackhmmer   #not required and will remove it\n",
        "    if install_jackhmmer:\n",
        "      os.system(f\"sudo apt install --quiet --yes hmmer\")\n",
        "      pbar.update(3)\n",
        "\n",
        "      # create a ramdisk to store a database chunk to make Jackhmmer run fast.\n",
        "      os.system(f\"sudo mkdir -m 777 --parents /tmp/ramdisk\")\n",
        "      os.system(f\"sudo mount -t tmpfs -o size=9G ramdisk /tmp/ramdisk\")\n",
        "      pbar.update(1)\n",
        "\n",
        "    else:\n",
        "      pbar.update(4)\n",
        "\n",
        "  else:\n",
        "    pbar.update(55)\n",
        "\n",
        "###############################################################################################\n",
        "####    Python imports \n",
        "###############################################################################################\n",
        "if 'alphafold' not in sys.path:\n",
        "  sys.path.append('alphafold')\n",
        "if 'ColabFold/beta' not in sys.path:\n",
        "  sys.path.append('ColabFold/beta')\n",
        "\n",
        "if f\"{TMP_DIR}/bin\" not in os.environ['PATH']:\n",
        "  os.environ['PATH'] += f\":{TMP_DIR}/bin:{TMP_DIR}/scripts\"\n",
        "\n",
        "import colabfold as cf\n",
        "import colabfold_alphafold as cf_af\n",
        "\n",
        "import json\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "try:\n",
        "  from google.colab import files\n",
        "  IN_COLAB = True\n",
        "except:\n",
        "  IN_COLAB = False\n",
        "\n",
        "!cd .."
      ],
      "metadata": {
        "id": "5sYM9t4T6J5G",
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bbiYErPlmEvp"
      },
      "outputs": [],
      "source": [
        "#@title Run Colabfold with reduced MSA\n",
        "#Code was taken from COLABFOLD git and modified for convenience \n",
        "import re\n",
        "import time\n",
        "from IPython.display import clear_output\n",
        "\n",
        "%cd /content/struct_gen/.\n",
        "#####################################################################################################################\n",
        "###    Input sequence\n",
        "#####################################################################################################################\n",
        "\n",
        "#@markdown Change this to the amino acid sequence of your system\n",
        "sequence = 'MQRGKVKWFNNEKGYGFIEVEGGSDVFVHFTAIQGEGFKTLEEGQEVSFEIVQGNRGPQAANVVKE' #@param {type:\"string\"}\n",
        "jobname = \"CSP\" #@param {type:\"string\"}\n",
        "homooligomer =  \"1\" #param {type:\"string\"}\n",
        "\n",
        "\n",
        "#####################################################################################################################\n",
        "###    MSA parameters\n",
        "#####################################################################################################################\n",
        "\n",
        "cd \n",
        "add_custom_msa = False \n",
        "msa_format = \"fas\" \n",
        "pair_mode = \"unpaired\" \n",
        "pair_cov = 50 \n",
        "pair_qid = 20 \n",
        "\n",
        "I = cf_af.prep_inputs(sequence, jobname, homooligomer, clean=IN_COLAB)\n",
        "msa_method = \"mmseqs2\" \n",
        "#I['output_dir']='_'.join(I['output_dir'].split('_')[:-1])\n",
        "I = cf_af.prep_msa(I, msa_method, add_custom_msa, msa_format,\n",
        "                   pair_mode, pair_cov, pair_qid, TMP_DIR=TMP_DIR)\n",
        "mod_I = I\n",
        "clear_output() # ----> Clear the output from previous functions\n",
        "#No relaxation \n",
        "num_relax = \"None\"\n",
        "\n",
        "\n",
        "#####################################################################################################################\n",
        "###    Parameters for running Alphafold\n",
        "#####################################################################################################################\n",
        "rank_by = \"pLDDT\" \n",
        "use_turbo = True \n",
        "#@markdown This parameter can be \"tuned\". Too low, and it doesn't have enough information for sensible predictions. Too high, and it will not generate structural diversity\n",
        "max_msa = \"08:16\" #@param [\"512:1024\", \"256:512\", \"128:256\", \"64:128\", \"32:64\",\"16:32\",\"08:16\",\"04:08\",\"02:04\",\"01:02\",\"02:02\"]\n",
        "#@markdown - `max_msa` defines: `max_msa_clusters:max_extra_msa` number of sequences to use. \n",
        "max_msa_clusters, max_extra_msa = [int(x) for x in max_msa.split(\":\")]\n",
        "\n",
        "show_images = False \n",
        "\n",
        "num_models = 5 \n",
        "use_ptm = True \n",
        "num_ensemble = 1 \n",
        "max_recycles = 1 \n",
        "is_training = True \n",
        "num_samples = 128 #@param [1,2,4,8,16,32,64,128] {type:\"raw\"}\n",
        "#@markdown - `num_samples` defines the number of random seed. (For each seed 5 different models are predicted)  \n",
        "subsample_msa = True \n",
        "\n",
        "if not use_ptm and rank_by == \"pTMscore\":\n",
        "  print(\"WARNING: models will be ranked by pLDDT, 'use_ptm' is needed to compute pTMscore\")\n",
        "  rank_by = \"pLDDT\"\n",
        "\n",
        "# prep input features\n",
        "feature_dict = cf_af.prep_feats(mod_I, clean=IN_COLAB)\n",
        "Ls_plot = feature_dict[\"Ls\"]\n",
        "\n",
        "# prep model options\n",
        "opt = {\"N\":len(feature_dict[\"msa\"]),\n",
        "       \"L\":len(feature_dict[\"residue_index\"]),\n",
        "       \"use_ptm\":use_ptm,\n",
        "       \"use_turbo\":use_turbo,\n",
        "       \"max_recycles\":max_recycles,\n",
        "       \"tol\":0.0,\n",
        "       \"num_ensemble\":num_ensemble,\n",
        "       \"max_msa_clusters\":max_msa_clusters,\n",
        "       \"max_extra_msa\":max_extra_msa,\n",
        "       \"is_training\":is_training}\n",
        "\n",
        "if use_turbo:\n",
        "  if \"runner\" in dir():\n",
        "    # only recompile if options changed\n",
        "    runner = cf_af.prep_model_runner(opt, old_runner=runner)\n",
        "  else:\n",
        "    runner = cf_af.prep_model_runner(opt)\n",
        "else:\n",
        "  runner = None\n",
        "\n",
        "#####################################################################################################################\n",
        "###    Run Alphafold with low MSA \n",
        "#####################################################################################################################\n",
        "t1 = time.perf_counter()\n",
        "outs, model_rank = cf_af.run_alphafold(feature_dict, opt, runner, num_models, num_samples, subsample_msa,\n",
        "                                       rank_by=rank_by, show_images=show_images)\n",
        "\n",
        "\n",
        "\n",
        "#####################################################################################################################\n",
        "###    Output folder\n",
        "#####################################################################################################################\n",
        "\n",
        "structures_path='/content/Structures'   #Output_folder\n",
        "os.makedirs(structures_path)\n",
        "file_path=os.path.join(structures_path,'file_details.txt')\n",
        "with open(file_path, \"w\") as file_details:\n",
        "  for n,key in enumerate(model_rank):\n",
        "    copy_line=f'cp {I[\"output_dir\"]}/rank_{n+1}_{key}_unrelaxed.pdb {structures_path}/pred_{n+1}.pdb'\n",
        "    os.system(copy_line)\n",
        "    if num_relax !=\"None\":\n",
        "      if n<num_relax: \n",
        "        copy_line2=f'cp {I[\"output_dir\"]}/rank_{n+1}_{key}_relaxed.pdb {structures_path}/pred_{n+1}.pdb'\n",
        "        os.system(copy_line2)\n",
        "    line = f\"pred_{n+1}.pdb pLDDT:{outs[key]['pLDDT']:.2f}\" + f\" pTMscore:{outs[key]['pTMscore']:.4f}\" if use_ptm else \"\"\n",
        "    file_details.write(line+\"\\n\")\n",
        "\n",
        "#os.system(f'rm -r {I[output_dir]}')   #--> run this line to delete the second copy of structures\n",
        "%cd /content/\n",
        "os.system(f'zip -FSr Structures.zip {structures_path}')\n",
        "t2 = time.perf_counter()\n",
        "clear_output()\n",
        "print('\\nTime taken to generate:',(t2-t1)/60,' mins')\n",
        "\n",
        "print(f'The structures can be found in {structures_path}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mek6Y0S3icAK",
        "cellView": "form"
      },
      "outputs": [],
      "source": [
        "#@title Install condacolab\n",
        "#@markdown After running this cell wait for the kernel to restart (~1min)\n",
        "\n",
        "#@markdown Then, start running the rest of the blocks\n",
        "try:\n",
        "    import google.colab\n",
        "    !pip install condacolab\n",
        "    import condacolab\n",
        "    condacolab.install()\n",
        "except ModuleNotFoundError:\n",
        "    pass"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Install OpenMM with Plumed\n",
        "#@markdown Run this to install and import libraries \n",
        "import time\n",
        "t1 = time.perf_counter()\n",
        "try:\n",
        "    import condacolab\n",
        "    from google.colab import files\n",
        "    from IPython.display import clear_output\n",
        "    condacolab.check()\n",
        "    !conda install -q -y -c conda-forge openmm cudatoolkit=11.2 openmmforcefields openmm-plumed \n",
        "    \n",
        "    # for gromacs forcefield files (for conversion from GMX)\n",
        "    %cd /content/Plumed-on-OpenMM-GPU/\n",
        "    !tar -zxvf gromacsff.tar.gz\n",
        "    %cp -r CSP_reqFiles /content/test_MD\n",
        "    %cd /content/test_MD\n",
        "    \n",
        "    on_colab = True\n",
        "    clear_output()             # clear the excessive installation outputs (disable incase of error check)\n",
        "    print(\"Dependencies successfully installed and imported!\")\n",
        "except ModuleNotFoundError:\n",
        "    on_colab = False\n",
        "\n",
        "!pwd\n",
        "\n",
        "# required for simulation with Plumed on gpu\n",
        "from sys import stdout\n",
        "from openmmplumed import PlumedForce\n",
        "from openmm.app import *\n",
        "from openmm import *\n",
        "from openmm.unit import *\n",
        "\n",
        "# required for analysis\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "t2 = time.perf_counter()\n",
        "print('time taken to run:',t2-t1)\n",
        "\n",
        "#create the directory for colabfold\n"
      ],
      "metadata": {
        "id": "G441cmKTjDYy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import os\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "!git clone https://github.com/bodhivani/RAVEfold\n",
        "\n",
        "!cp RAVEfold/ravefuncs.py .\n",
        "import ravefuncs as rave"
      ],
      "metadata": {
        "id": "6toIzQOnaRgy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Cluster to initialize RAVEfold\n",
        "if os.path.isdir(\"Structures\")==False:\n",
        "  !unzip RAVEfold/CSPdata/Structures.zip .\n",
        "\n",
        "rave.RegSpaceClustering()"
      ],
      "metadata": {
        "id": "4fj1dIUdcn0W"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Unbiased simulations\n",
        "\n",
        "#@markdown Here we are using already solvated and equilibrated system(from GMX)\n",
        "\n",
        "# Inputs definition \n",
        "\n",
        "#@markdown Check the below box to run on GPU\n",
        "on_gpu=True #@param {type:\"boolean\"}\n",
        "#@markdown MD parameters\n",
        "\n",
        "#@markdown Integration Timestep (ps)\n",
        "dt =0.002 #@param{type:\"number\"}\n",
        "#@markdown Temperature (K)\n",
        "temp=300 #@param{type:\"number\"}\n",
        "freq=1 #param{type:\"number\"}\n",
        "#@markdown Number of steps \n",
        "nstep=500000 #@param{type:\"number\"}\n",
        "#@markdown Plumed file\n",
        "plumedfile=\"plumed_full.dat\" #@param{type:\"string\"}\n",
        "\n",
        "os.mkdir(\"unbiased\")\n",
        "os.chdir(\"unbiased\")\n",
        "for index in listindices:\n",
        "  os.mkdir(\"%i\"%index)\n",
        "  os.cp(\"Structures/pred_%i/ %i\"%(index,index))\n",
        "  os.chdir(\"%i\"%(index))\n",
        "  run_unbiased(on_gpu,dt,temp,freq,nstep,index)\n",
        "  os.chdir(\"..\")\n",
        "\n",
        "os.chdir(\"..\")\n"
      ],
      "metadata": {
        "id": "N79bx1VRhR0l"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title SPIB on unbiased simulations\n",
        "cvs=[]\n",
        "os.mkdir(\"SPIB_unbiased\")\n",
        "os.chdir(\"SPIB_unbiased\")\n",
        "\n",
        "for i,index in enumerate(listindices):\n",
        "    cvs.append(np.loadtxt(\"../unbiased/%i/colvar.dat\"%index))\n",
        "    np.save(\"colvar_%i_unb.npy\"%i,cvs[i])\n",
        "    lentraj=len(cvs[i])\n",
        "    zeroone=np.hstack([np.zeros(int(lentraj/2),dtype=np.int8),np.ones(lentraj-int(lentraj/2),dtype=np.int8)])\n",
        "    initlabels=np.eye(num_state)[zeroone+int(i*2)]\n",
        "    np.save(\"labels_%i_unb.npy\"%i,initlabels)\n",
        "\n",
        "!cp RAVEfold/sample_config.ini config.ini\n",
        "\n",
        "f= open(\"sample_config.ini\",\"a\")\n",
        "\n",
        "f.write(\"\\n traj_data = [%s]\"%(\",\".join[\"colvar_%i_unb.npy\"%i for i in len(cvs)]))\n",
        "\n",
        "f.write(\"\\n initial_labels = [%s]\"%(\",\".join[\"labels_%i_unb.npy\"%i for i in len(cvs)]))"
      ],
      "metadata": {
        "id": "KWQ7j8YykTvd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%run State-Predictive-Information-Bottleneck/test_model_advanced.py config.ini"
      ],
      "metadata": {
        "id": "bYSHlVCX0_Tk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "prefix='SPIB/Unweighted_d=1_t=50_b=0.0100_learn=0.001000_'\n",
        "weights=np.load(prefix+\"z_mean_encoder_weight0.npy\")\n",
        "plt.plot(weights)\n",
        "\n",
        "lspace=[np.load(prefix+\"traj%i_mean_representation0.npy\"%i) for i in range(len(cvs))]\n"
      ],
      "metadata": {
        "id": "n8zoCgHE9OHe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Biased simulations\n",
        "\n",
        "#@markdown Here we are using already solvated and equilibrated system(from GMX)\n",
        "\n",
        "# Inputs definition \n",
        "\n",
        "#@markdown metadynamics parameters\n",
        "height = 1.5 #@param{type:\"number\"}\n",
        "biasfactor=10 #@param{type:\"number\"}\n",
        "#@markdown standard deviation of deposited gaussians\n",
        "width1= 1 #@param{type:\"number\"}\n",
        "width2= 1 #@param{type:\"number\"}\n",
        "#@markdown metadynamics gridparameters\n",
        "gridmin1=1 #@param{type:\"number\"}\n",
        "gridmin2=1 #@param{type:\"number\"}\n",
        "gridmax1=1 #@param{type:\"number\"}\n",
        "gridmax2=1 #@param{type:\"number\"}\n",
        "#@markdown Length of metadynamics simulation\n",
        "\n",
        "\n",
        "!cp RAVEfold/CSPdata/plumed_full.dat . plumed_biased.dat\n",
        "colvar=\"sc1_r1,cc1_r1,sc1_r2,cc1_r2,sc1_r3,cc1_r3,sc1_r5,cc1_r5,sc1_r6,cc1_r6,sc1_r7,cc1_r7,sc1_r8,cc1_r8,sc1_r9,cc1_r9,sc1_r10,cc1_r10,sc1_r11,cc1_r11,sc1_r12,cc1_r12,sc1_r13,cc1_r13,sc1_r15,cc1_r15,sc1_r17,cc1_r17,sc1_r18,cc1_r18,sc1_r19,cc1_r19,sc1_r20,cc1_r20,sc1_r21,cc1_r21,sc1_r24,cc1_r24,sc1_r25,cc1_r25,sc1_r26,cc1_r26,sc1_r27,cc1_r27,sc1_r28,cc1_r28,sc1_r29,cc1_r29,sc1_r30,cc1_r30,sc1_r31,cc1_r31,sc1_r33,cc1_r33,sc1_r34,cc1_r34,sc1_r36,cc1_r36,sc1_r38,cc1_r38,sc1_r39,cc1_r39,sc1_r40,cc1_r40,sc1_r41,cc1_r41,sc1_r42,cc1_r42,sc1_r43,cc1_r43,sc1_r45,cc1_r45,sc1_r46,cc1_r46,sc1_r47,cc1_r47,sc1_r48,cc1_r48,sc1_r49,cc1_r49,sc1_r50,cc1_r50,sc1_r51,cc1_r51,sc1_r52,cc1_r52,sc1_r53,cc1_r53,sc1_r55,cc1_r55,sc1_r56,cc1_r56,sc1_r58,cc1_r58,sc1_r59,cc1_r59,sc1_r62,cc1_r62,sc1_r63,cc1_r63,sc1_r64,cc1_r64,sc1_r65,cc1_r65,sc1_r66,cc1_r66,sc2_r1,cc2_r1,sc2_r2,cc2_r2,sc2_r3,cc2_r3,sc2_r5,cc2_r5,sc2_r7,cc2_r7,sc2_r8,cc2_r8,sc2_r9,cc2_r9,sc2_r10,cc2_r10,sc2_r11,cc2_r11,sc2_r12,cc2_r12,sc2_r13,cc2_r13,sc2_r15,cc2_r15,sc2_r17,cc2_r17,sc2_r18,cc2_r18,sc2_r19,cc2_r19,sc2_r21,cc2_r21,sc2_r25,cc2_r25,sc2_r27,cc2_r27,sc2_r29,cc2_r29,sc2_r30,cc2_r30,sc2_r33,cc2_r33,sc2_r34,cc2_r34,sc2_r36,cc2_r36,sc2_r38,cc2_r38,sc2_r39,cc2_r39,sc2_r41,cc2_r41,sc2_r42,cc2_r42,sc2_r43,cc2_r43,sc2_r45,cc2_r45,sc2_r46,cc2_r46,sc2_r49,cc2_r49,sc2_r50,cc2_r50,sc2_r51,cc2_r51,sc2_r53,cc2_r53,sc2_r55,cc2_r55,sc2_r56,cc2_r56,sc2_r58,cc2_r58,sc2_r59,cc2_r59,sc2_r62,cc2_r62,sc2_r65,cc2_r65,sc2_r66,cc2_r66,sc3_r1,cc3_r1,sc3_r2,cc3_r2,sc3_r3,cc3_r3,sc3_r5,cc3_r5,sc3_r7,cc3_r7,sc3_r12,cc3_r12,sc3_r13,cc3_r13,sc3_r19,cc3_r19,sc3_r21,cc3_r21,sc3_r34,cc3_r34,sc3_r36,cc3_r36,sc3_r39,cc3_r39,sc3_r42,cc3_r42,sc3_r43,cc3_r43,sc3_r45,cc3_r45,sc3_r46,cc3_r46,sc3_r50,cc3_r50,sc3_r53,cc3_r53,sc3_r56,cc3_r56,sc3_r59,cc3_r59,sc3_r65,cc3_r65,sc3_r66,cc3_r66,sc4_r3,cc4_r3,sc4_r5,cc4_r5,sc4_r7,cc4_r7,sc4_r13,cc4_r13,sc4_r39,cc4_r39,sc4_r56,cc4_r56,sc4_r65,cc4_r65,sc5_r3,cc5_r3,sc5_r56,cc5_r56\"\n",
        "plumedfile=\"plumed_biased.dat\"\n",
        "make_biased_plumed(plumedfile,weights,colvar,height,biasfactor,width1,width2,gridmin1,gridmin2,gridmax1,gridmax2)\n",
        "\n",
        "pdbfile=\"Structures/pred_1.pdb\"\n",
        "run_biased_plumed(pdbfile,time)"
      ],
      "metadata": {
        "id": "vyi3j_Hp1R_3"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}